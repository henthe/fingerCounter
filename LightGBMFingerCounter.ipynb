{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.9.0.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: absl-py in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from mediapipe) (3.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from mediapipe) (1.21.6)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from mediapipe) (4.8.1.78)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from attrs>=19.1.0->mediapipe) (6.7.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->attrs>=19.1.0->mediapipe) (3.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe opencv-python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r'C:\\Users\\henri\\Documents\\FingerCounterData\\DatasetForFingerCounter'\n",
    "training_path = path + r'\\training_landmarks.csv'\n",
    "training_path\n",
    "# Write the DataFrame to a CSV file\n",
    "df = pd.read_csv(training_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[['x0','y0','z0','x1','y1','z1','x2','y2','z2','x3','y3','z3','x4','y4','z4','x5','y5','z5','x6','y6','z6','x7','y7','z7','x8','y8','z8','x9','y9','z9','x10','y10','z10','x11','y11','z11','x12','y12','z12','x13','y13','z13','x14','y14','z14','x15','y15','z15','x16','y16','z16','x17','y17','z17','x18','y18','z18','x19','y19','z19','x20','y20','z20']]\n",
    "y_train = df['image']\n",
    "y_train = y_train.map(lambda image: image.split('_')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the lightgbm model\n",
    "import lightgbm as lgb\n",
    "#clf = lgb.LGBMClassifier()\n",
    "#clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\henri\\Documents\\FingerCounterData\\DatasetForFingerCounter'\n",
    "training_path = path + r'\\test_landmarks.csv'\n",
    "# Write the DataFrame to a CSV file\n",
    "df = pd.read_csv(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df[['x0','y0','z0','x1','y1','z1','x2','y2','z2','x3','y3','z3','x4','y4','z4','x5','y5','z5','x6','y6','z6','x7','y7','z7','x8','y8','z8','x9','y9','z9','x10','y10','z10','x11','y11','z11','x12','y12','z12','x13','y13','z13','x14','y14','z14','x15','y15','z15','x16','y16','z16','x17','y17','z17','x18','y18','z18','x19','y19','z19','x20','y20','z20']]\n",
    "y_test = df['image']\n",
    "y_test = y_test.map(lambda image: image.split('_')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurements and Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best num_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Test set score: 0.7225\n",
      "3\n",
      "Test set score: 0.8325\n",
      "4\n",
      "Test set score: 0.8586\n",
      "5\n",
      "Test set score: 0.8743\n",
      "6\n",
      "Test set score: 0.8639\n",
      "7\n",
      "Test set score: 0.9005\n",
      "8\n",
      "Test set score: 0.9058\n",
      "9\n",
      "Test set score: 0.9005\n",
      "10\n",
      "Test set score: 0.9162\n",
      "11\n",
      "Test set score: 0.9005\n",
      "12\n",
      "Test set score: 0.9058\n",
      "13\n",
      "Test set score: 0.9058\n",
      "14\n",
      "Test set score: 0.9110\n",
      "15\n",
      "Test set score: 0.9058\n",
      "16\n",
      "Test set score: 0.9058\n",
      "17\n",
      "Test set score: 0.9110\n",
      "18\n",
      "Test set score: 0.9162\n",
      "19\n",
      "Test set score: 0.9058\n",
      "20\n",
      "Test set score: 0.9110\n",
      "21\n",
      "Test set score: 0.9058\n",
      "22\n",
      "Test set score: 0.9058\n",
      "23\n",
      "Test set score: 0.9005\n",
      "24\n",
      "Test set score: 0.9005\n",
      "25\n",
      "Test set score: 0.9005\n",
      "26\n",
      "Test set score: 0.9110\n",
      "27\n",
      "Test set score: 0.8953\n",
      "28\n",
      "Test set score: 0.9005\n",
      "29\n",
      "Test set score: 0.8953\n",
      "30\n",
      "Test set score: 0.8953\n",
      "31\n",
      "Test set score: 0.9005\n",
      "32\n",
      "Test set score: 0.9110\n",
      "33\n",
      "Test set score: 0.9005\n",
      "34\n",
      "Test set score: 0.8953\n",
      "35\n",
      "Test set score: 0.9058\n",
      "36\n",
      "Test set score: 0.8953\n",
      "37\n",
      "Test set score: 0.9005\n",
      "38\n",
      "Test set score: 0.8901\n",
      "39\n",
      "Test set score: 0.8901\n",
      "40\n",
      "Test set score: 0.8953\n",
      "41\n",
      "Test set score: 0.8953\n",
      "42\n",
      "Test set score: 0.8901\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12064\\650345510.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_leaves\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1154\u001b[0m             \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m         )\n\u001b[0;32m   1158\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m         )\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    274\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3658\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   3659\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3660\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   3661\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3662\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build the lightgbm model\n",
    "data = []\n",
    "import lightgbm as lgb\n",
    "for i in range(2,100):\n",
    "    clf = lgb.LGBMClassifier(num_leaves=i,verbose=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    data.append([i,clf.score(X_test, y_test)])\n",
    "    print(i)\n",
    "    print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))\n",
    "print(\"highest score:\")    \n",
    "print(max(data, key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best num_leaves = 10!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Test set score: 0.9162\n",
      "2\n",
      "Test set score: 0.9110\n",
      "3\n",
      "Test set score: 0.9058\n",
      "4\n",
      "Test set score: 0.8953\n",
      "5\n",
      "Test set score: 0.9110\n",
      "6\n",
      "Test set score: 0.8953\n",
      "7\n",
      "Test set score: 0.8953\n",
      "8\n",
      "Test set score: 0.9005\n",
      "9\n",
      "Test set score: 0.1885\n",
      "highest score:\n",
      "[1, 0.9162303664921466]\n"
     ]
    }
   ],
   "source": [
    "# build the lightgbm model\n",
    "data = []\n",
    "import lightgbm as lgb\n",
    "for i in range(1,10):\n",
    "    clf = lgb.LGBMClassifier(num_leaves=10,verbose=-1, learning_rate=i/10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    data.append([i,clf.score(X_test, y_test)])\n",
    "    print(i)\n",
    "    print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))\n",
    "print(\"highest score:\")    \n",
    "print(max(data, key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best learning_rate = 0.1 => default!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "Test set score: 0.9162\n",
      "0\n",
      "Test set score: 0.9162\n",
      "1\n",
      "Test set score: 0.7225\n",
      "2\n",
      "Test set score: 0.8639\n",
      "3\n",
      "Test set score: 0.8848\n",
      "4\n",
      "Test set score: 0.8796\n",
      "5\n",
      "Test set score: 0.9110\n",
      "6\n",
      "Test set score: 0.9058\n",
      "7\n",
      "Test set score: 0.9110\n",
      "8\n",
      "Test set score: 0.9110\n",
      "9\n",
      "Test set score: 0.9162\n",
      "10\n",
      "Test set score: 0.9162\n",
      "11\n",
      "Test set score: 0.9162\n",
      "12\n",
      "Test set score: 0.9162\n",
      "13\n",
      "Test set score: 0.9162\n",
      "14\n",
      "Test set score: 0.9162\n",
      "15\n",
      "Test set score: 0.9162\n",
      "16\n",
      "Test set score: 0.9162\n",
      "17\n",
      "Test set score: 0.9162\n",
      "18\n",
      "Test set score: 0.9162\n",
      "19\n",
      "Test set score: 0.9162\n",
      "20\n",
      "Test set score: 0.9162\n",
      "21\n",
      "Test set score: 0.9162\n",
      "22\n",
      "Test set score: 0.9162\n",
      "23\n",
      "Test set score: 0.9162\n",
      "24\n",
      "Test set score: 0.9162\n",
      "25\n",
      "Test set score: 0.9162\n",
      "26\n",
      "Test set score: 0.9162\n",
      "27\n",
      "Test set score: 0.9162\n",
      "28\n",
      "Test set score: 0.9162\n",
      "29\n",
      "Test set score: 0.9162\n",
      "30\n",
      "Test set score: 0.9162\n",
      "31\n",
      "Test set score: 0.9162\n",
      "32\n",
      "Test set score: 0.9162\n",
      "33\n",
      "Test set score: 0.9162\n",
      "34\n",
      "Test set score: 0.9162\n",
      "35\n",
      "Test set score: 0.9162\n",
      "36\n",
      "Test set score: 0.9162\n",
      "37\n",
      "Test set score: 0.9162\n",
      "38\n",
      "Test set score: 0.9162\n",
      "39\n",
      "Test set score: 0.9162\n",
      "40\n",
      "Test set score: 0.9162\n",
      "41\n",
      "Test set score: 0.9162\n",
      "42\n",
      "Test set score: 0.9162\n",
      "43\n",
      "Test set score: 0.9162\n",
      "44\n",
      "Test set score: 0.9162\n",
      "45\n",
      "Test set score: 0.9162\n",
      "46\n",
      "Test set score: 0.9162\n",
      "47\n",
      "Test set score: 0.9162\n",
      "48\n",
      "Test set score: 0.9162\n",
      "49\n",
      "Test set score: 0.9162\n",
      "50\n",
      "Test set score: 0.9162\n",
      "51\n",
      "Test set score: 0.9162\n",
      "52\n",
      "Test set score: 0.9162\n",
      "53\n",
      "Test set score: 0.9162\n",
      "54\n",
      "Test set score: 0.9162\n",
      "55\n",
      "Test set score: 0.9162\n",
      "56\n",
      "Test set score: 0.9162\n",
      "57\n",
      "Test set score: 0.9162\n",
      "58\n",
      "Test set score: 0.9162\n",
      "59\n",
      "Test set score: 0.9162\n",
      "60\n",
      "Test set score: 0.9162\n",
      "61\n",
      "Test set score: 0.9162\n",
      "62\n",
      "Test set score: 0.9162\n",
      "63\n",
      "Test set score: 0.9162\n",
      "64\n",
      "Test set score: 0.9162\n",
      "65\n",
      "Test set score: 0.9162\n",
      "66\n",
      "Test set score: 0.9162\n",
      "67\n",
      "Test set score: 0.9162\n",
      "68\n",
      "Test set score: 0.9162\n",
      "69\n",
      "Test set score: 0.9162\n",
      "70\n",
      "Test set score: 0.9162\n",
      "71\n",
      "Test set score: 0.9162\n",
      "72\n",
      "Test set score: 0.9162\n",
      "73\n",
      "Test set score: 0.9162\n",
      "74\n",
      "Test set score: 0.9162\n",
      "75\n",
      "Test set score: 0.9162\n",
      "76\n",
      "Test set score: 0.9162\n",
      "77\n",
      "Test set score: 0.9162\n",
      "78\n",
      "Test set score: 0.9162\n",
      "79\n",
      "Test set score: 0.9162\n",
      "80\n",
      "Test set score: 0.9162\n",
      "81\n",
      "Test set score: 0.9162\n",
      "82\n",
      "Test set score: 0.9162\n",
      "83\n",
      "Test set score: 0.9162\n",
      "84\n",
      "Test set score: 0.9162\n",
      "85\n",
      "Test set score: 0.9162\n",
      "86\n",
      "Test set score: 0.9162\n",
      "87\n",
      "Test set score: 0.9162\n",
      "88\n",
      "Test set score: 0.9162\n",
      "89\n",
      "Test set score: 0.9162\n",
      "90\n",
      "Test set score: 0.9162\n",
      "91\n",
      "Test set score: 0.9162\n",
      "92\n",
      "Test set score: 0.9162\n",
      "93\n",
      "Test set score: 0.9162\n",
      "94\n",
      "Test set score: 0.9162\n",
      "95\n",
      "Test set score: 0.9162\n",
      "96\n",
      "Test set score: 0.9162\n",
      "97\n",
      "Test set score: 0.9162\n",
      "98\n",
      "Test set score: 0.9162\n",
      "99\n",
      "Test set score: 0.9162\n",
      "highest score:\n",
      "[-1, 0.9162303664921466]\n"
     ]
    }
   ],
   "source": [
    "# build the lightgbm model\n",
    "data = []\n",
    "import lightgbm as lgb\n",
    "for i in range(-1,100):\n",
    "    clf = lgb.LGBMClassifier(num_leaves=10,verbose=-1,max_depth=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    data.append([i,clf.score(X_test, y_test)])\n",
    "    print(i)\n",
    "    print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))\n",
    "print(\"highest score:\")    \n",
    "print(max(data, key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best max_depth = -1 => default!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best min_data_in_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Test set score: 0.9110\n",
      "2\n",
      "Test set score: 0.8953\n",
      "3\n",
      "Test set score: 0.9162\n",
      "4\n",
      "Test set score: 0.9058\n",
      "5\n",
      "Test set score: 0.9162\n",
      "6\n",
      "Test set score: 0.9005\n",
      "7\n",
      "Test set score: 0.9005\n",
      "8\n",
      "Test set score: 0.9162\n",
      "9\n",
      "Test set score: 0.8953\n",
      "10\n",
      "Test set score: 0.9110\n",
      "11\n",
      "Test set score: 0.9005\n",
      "12\n",
      "Test set score: 0.9267\n",
      "13\n",
      "Test set score: 0.9058\n",
      "14\n",
      "Test set score: 0.9058\n",
      "15\n",
      "Test set score: 0.8901\n",
      "16\n",
      "Test set score: 0.9110\n",
      "17\n",
      "Test set score: 0.9110\n",
      "18\n",
      "Test set score: 0.9058\n",
      "19\n",
      "Test set score: 0.8901\n",
      "20\n",
      "Test set score: 0.9162\n",
      "21\n",
      "Test set score: 0.9005\n",
      "22\n",
      "Test set score: 0.9058\n",
      "23\n",
      "Test set score: 0.8953\n",
      "24\n",
      "Test set score: 0.8953\n",
      "25\n",
      "Test set score: 0.9005\n",
      "26\n",
      "Test set score: 0.8953\n",
      "27\n",
      "Test set score: 0.9110\n",
      "28\n",
      "Test set score: 0.8953\n",
      "29\n",
      "Test set score: 0.9110\n",
      "30\n",
      "Test set score: 0.8953\n",
      "31\n",
      "Test set score: 0.9005\n",
      "32\n",
      "Test set score: 0.9005\n",
      "33\n",
      "Test set score: 0.8901\n",
      "34\n",
      "Test set score: 0.8901\n",
      "35\n",
      "Test set score: 0.9005\n",
      "36\n",
      "Test set score: 0.9110\n",
      "37\n",
      "Test set score: 0.9005\n",
      "38\n",
      "Test set score: 0.9110\n",
      "39\n",
      "Test set score: 0.9215\n",
      "40\n",
      "Test set score: 0.9215\n",
      "41\n",
      "Test set score: 0.8953\n",
      "42\n",
      "Test set score: 0.9110\n",
      "43\n",
      "Test set score: 0.8953\n",
      "44\n",
      "Test set score: 0.8953\n",
      "45\n",
      "Test set score: 0.9058\n",
      "46\n",
      "Test set score: 0.9110\n",
      "47\n",
      "Test set score: 0.9215\n",
      "48\n",
      "Test set score: 0.9005\n",
      "49\n",
      "Test set score: 0.9110\n",
      "50\n",
      "Test set score: 0.9110\n",
      "51\n",
      "Test set score: 0.9005\n",
      "52\n",
      "Test set score: 0.8901\n",
      "53\n",
      "Test set score: 0.9110\n",
      "54\n",
      "Test set score: 0.8953\n",
      "55\n",
      "Test set score: 0.8848\n",
      "56\n",
      "Test set score: 0.9058\n",
      "57\n",
      "Test set score: 0.9005\n",
      "58\n",
      "Test set score: 0.9005\n",
      "59\n",
      "Test set score: 0.9005\n",
      "60\n",
      "Test set score: 0.9005\n",
      "61\n",
      "Test set score: 0.8953\n",
      "62\n",
      "Test set score: 0.9058\n",
      "63\n",
      "Test set score: 0.9005\n",
      "64\n",
      "Test set score: 0.9058\n",
      "65\n",
      "Test set score: 0.9162\n",
      "66\n",
      "Test set score: 0.8901\n",
      "67\n",
      "Test set score: 0.9058\n",
      "68\n",
      "Test set score: 0.8848\n",
      "69\n",
      "Test set score: 0.8953\n",
      "70\n",
      "Test set score: 0.9058\n",
      "71\n",
      "Test set score: 0.9005\n",
      "72\n",
      "Test set score: 0.9005\n",
      "73\n",
      "Test set score: 0.8901\n",
      "74\n",
      "Test set score: 0.8848\n",
      "75\n",
      "Test set score: 0.9058\n",
      "76\n",
      "Test set score: 0.9058\n",
      "77\n",
      "Test set score: 0.9005\n",
      "78\n",
      "Test set score: 0.9058\n",
      "79\n",
      "Test set score: 0.9005\n",
      "80\n",
      "Test set score: 0.9005\n",
      "81\n",
      "Test set score: 0.9005\n",
      "82\n",
      "Test set score: 0.9058\n",
      "83\n",
      "Test set score: 0.9005\n",
      "84\n",
      "Test set score: 0.9058\n",
      "85\n",
      "Test set score: 0.9058\n",
      "86\n",
      "Test set score: 0.8953\n",
      "87\n",
      "Test set score: 0.8953\n",
      "88\n",
      "Test set score: 0.8953\n",
      "89\n",
      "Test set score: 0.9058\n",
      "90\n",
      "Test set score: 0.9005\n",
      "91\n",
      "Test set score: 0.9110\n",
      "92\n",
      "Test set score: 0.8901\n",
      "93\n",
      "Test set score: 0.9058\n",
      "94\n",
      "Test set score: 0.9005\n",
      "95\n",
      "Test set score: 0.9005\n",
      "96\n",
      "Test set score: 0.8953\n",
      "97\n",
      "Test set score: 0.9005\n",
      "98\n",
      "Test set score: 0.9005\n",
      "99\n",
      "Test set score: 0.9058\n",
      "highest score:\n",
      "[12, 0.9267015706806283]\n"
     ]
    }
   ],
   "source": [
    "# build the lightgbm model\n",
    "data = []\n",
    "import lightgbm as lgb\n",
    "for i in range(1,100):\n",
    "    clf = lgb.LGBMClassifier(num_leaves=10,verbose=-1,min_data_in_leaf=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    data.append([i,clf.score(X_test, y_test)])\n",
    "    print(i)\n",
    "    print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))\n",
    "print(\"highest score:\")    \n",
    "print(max(data, key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best min_data_in_leaf = 12!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best min_sum_heassian_in_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Test set score: 0.9267\n",
      "2\n",
      "Test set score: 0.9267\n",
      "3\n",
      "Test set score: 0.9162\n",
      "4\n",
      "Test set score: 0.9267\n",
      "5\n",
      "Test set score: 0.9110\n",
      "6\n",
      "Test set score: 0.9267\n",
      "7\n",
      "Test set score: 0.9110\n",
      "8\n",
      "Test set score: 0.9058\n",
      "9\n",
      "Test set score: 0.8953\n",
      "10\n",
      "Test set score: 0.9110\n",
      "11\n",
      "Test set score: 0.9058\n",
      "12\n",
      "Test set score: 0.9162\n",
      "13\n",
      "Test set score: 0.9162\n",
      "14\n",
      "Test set score: 0.9058\n",
      "15\n",
      "Test set score: 0.9058\n",
      "16\n",
      "Test set score: 0.8953\n",
      "17\n",
      "Test set score: 0.9005\n",
      "18\n",
      "Test set score: 0.9005\n",
      "19\n",
      "Test set score: 0.9058\n",
      "20\n",
      "Test set score: 0.9058\n",
      "21\n",
      "Test set score: 0.8953\n",
      "22\n",
      "Test set score: 0.9058\n",
      "23\n",
      "Test set score: 0.9110\n",
      "24\n",
      "Test set score: 0.9110\n",
      "25\n",
      "Test set score: 0.9058\n",
      "26\n",
      "Test set score: 0.9162\n",
      "27\n",
      "Test set score: 0.9162\n",
      "28\n",
      "Test set score: 0.9058\n",
      "29\n",
      "Test set score: 0.9110\n",
      "30\n",
      "Test set score: 0.9215\n",
      "31\n",
      "Test set score: 0.9110\n",
      "32\n",
      "Test set score: 0.9058\n",
      "33\n",
      "Test set score: 0.9110\n",
      "34\n",
      "Test set score: 0.9110\n",
      "35\n",
      "Test set score: 0.9058\n",
      "36\n",
      "Test set score: 0.9005\n",
      "37\n",
      "Test set score: 0.8953\n",
      "38\n",
      "Test set score: 0.9058\n",
      "39\n",
      "Test set score: 0.9058\n",
      "40\n",
      "Test set score: 0.8953\n",
      "41\n",
      "Test set score: 0.9110\n",
      "42\n",
      "Test set score: 0.9110\n",
      "43\n",
      "Test set score: 0.9162\n",
      "44\n",
      "Test set score: 0.9110\n",
      "45\n",
      "Test set score: 0.9005\n",
      "46\n",
      "Test set score: 0.9005\n",
      "47\n",
      "Test set score: 0.8953\n",
      "48\n",
      "Test set score: 0.8953\n",
      "49\n",
      "Test set score: 0.9058\n",
      "50\n",
      "Test set score: 0.9162\n",
      "51\n",
      "Test set score: 0.9058\n",
      "52\n",
      "Test set score: 0.9058\n",
      "53\n",
      "Test set score: 0.8901\n",
      "54\n",
      "Test set score: 0.9110\n",
      "55\n",
      "Test set score: 0.9058\n",
      "56\n",
      "Test set score: 0.9110\n",
      "57\n",
      "Test set score: 0.9058\n",
      "58\n",
      "Test set score: 0.9110\n",
      "59\n",
      "Test set score: 0.9005\n",
      "60\n",
      "Test set score: 0.9005\n",
      "61\n",
      "Test set score: 0.9058\n",
      "62\n",
      "Test set score: 0.9005\n",
      "63\n",
      "Test set score: 0.9058\n",
      "64\n",
      "Test set score: 0.8953\n",
      "65\n",
      "Test set score: 0.8953\n",
      "66\n",
      "Test set score: 0.9162\n",
      "67\n",
      "Test set score: 0.9110\n",
      "68\n",
      "Test set score: 0.9110\n",
      "69\n",
      "Test set score: 0.8953\n",
      "70\n",
      "Test set score: 0.9005\n",
      "71\n",
      "Test set score: 0.9005\n",
      "72\n",
      "Test set score: 0.8953\n",
      "73\n",
      "Test set score: 0.9110\n",
      "74\n",
      "Test set score: 0.8953\n",
      "75\n",
      "Test set score: 0.9058\n",
      "76\n",
      "Test set score: 0.9005\n",
      "77\n",
      "Test set score: 0.9110\n",
      "78\n",
      "Test set score: 0.9215\n",
      "79\n",
      "Test set score: 0.9005\n",
      "80\n",
      "Test set score: 0.9005\n",
      "81\n",
      "Test set score: 0.9005\n",
      "82\n",
      "Test set score: 0.8901\n",
      "83\n",
      "Test set score: 0.9110\n",
      "84\n",
      "Test set score: 0.9058\n",
      "85\n",
      "Test set score: 0.9058\n",
      "86\n",
      "Test set score: 0.9110\n",
      "87\n",
      "Test set score: 0.8901\n",
      "88\n",
      "Test set score: 0.8901\n",
      "89\n",
      "Test set score: 0.9005\n",
      "90\n",
      "Test set score: 0.9005\n",
      "91\n",
      "Test set score: 0.9005\n",
      "92\n",
      "Test set score: 0.9005\n",
      "93\n",
      "Test set score: 0.8953\n",
      "94\n",
      "Test set score: 0.8953\n",
      "95\n",
      "Test set score: 0.9058\n",
      "96\n",
      "Test set score: 0.9110\n",
      "97\n",
      "Test set score: 0.8953\n",
      "98\n",
      "Test set score: 0.9058\n",
      "99\n",
      "Test set score: 0.9110\n",
      "highest score:\n",
      "[1, 0.9267015706806283]\n"
     ]
    }
   ],
   "source": [
    "# build the lightgbm model\n",
    "data = []\n",
    "import lightgbm as lgb\n",
    "for i in range(1,100):\n",
    "    clf = lgb.LGBMClassifier(num_leaves=10,verbose=-1,min_data_in_leaf=12,min_sum_hessian_in_leaf=i/100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    data.append([i,clf.score(X_test, y_test)])\n",
    "    print(i)\n",
    "    print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))\n",
    "print(\"highest score:\")    \n",
    "print(max(data, key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best min_sum_hessian_in_leaf = 0.001 => default!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the results\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "# view accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "#print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.0000\n",
      "Test set score: 0.8901\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(clf.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[21  2  1  5  0  0  0]\n",
      " [ 0 27  2  0  1  1  0]\n",
      " [ 0  0 23  0  0  0  0]\n",
      " [ 1  2  0 31  0  0  1]\n",
      " [ 0  1  0  0 25  2  0]\n",
      " [ 1  0  0  0  0 20  0]\n",
      " [ 0  0  1  0  0  0 23]]\n",
      "\n",
      "True Positives(TP) =  21\n",
      "\n",
      "True Negatives(TN) =  27\n",
      "\n",
      "False Positives(FP) =  2\n",
      "\n",
      "False Negatives(FN) =  0\n"
     ]
    }
   ],
   "source": [
    "# view confusion-matrix\n",
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialisieren von MediaPipe und Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "# Pfad zum Bild auf Ihrer Festplatte\n",
    "image_path = \"C:/Users/henri/Documents/testData/image_spock_13.jpg\" #add your path\n",
    "\n",
    "# Bild einlesen\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# BGR 2 RGB\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detections\n",
    "with hands:\n",
    "    results = hands.process(image_rgb)\n",
    "    \n",
    "# Extrahieren der Koordinaten der Handlandmarken\n",
    "landmark_coords = {}\n",
    "if results.multi_hand_landmarks:\n",
    "    for i, landmark in enumerate(results.multi_hand_landmarks[0].landmark):\n",
    "        landmark_coords[f'x{i+1}'] = landmark.x\n",
    "        landmark_coords[f'y{i+1}'] = landmark.y\n",
    "        landmark_coords[f'z{i+1}'] = landmark.z\n",
    "\n",
    "    # Ausgabe der Koordinaten\n",
    "\n",
    "\n",
    "    # Erstellen eines Pandas DataFrame aus dem Dictionary\n",
    "    df = pd.DataFrame([landmark_coords])\n",
    "\n",
    "\n",
    "    y_pred=clf.predict(df)\n",
    "    print(y_pred)\n",
    "else:\n",
    "    print('no hand detected')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

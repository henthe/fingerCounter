{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScikitLearnFingerCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the necessary python libraries\n",
    "!pip install numpy\n",
    "import numpy as np\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\alex\\Documents\\DeepLearning\\DatasetForFingerCounter\"\n",
    "training_path = path + r'\\Training_landmarks.csv'\n",
    "test_path = path + r'\\Test_landmarks.csv'\n",
    "validation_path = path + r'\\Validation_landmarks.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "df_train = pd.read_csv(training_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "df_validation = pd.read_csv(validation_path)\n",
    "#Print the first 5 rows of the dataframe.\n",
    "df_train.head()\n",
    "df_test.head()\n",
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "X_train = df_train[['x0','y0','z0','x1','y1','z1','x2','y2','z2','x3','y3','z3','x4','y4','z4','x5','y5','z5','x6','y6','z6','x7','y7','z7','x8','y8','z8','x9','y9','z9','x10','y10','z10','x11','y11','z11','x12','y12','z12','x13','y13','z13','x14','y14','z14','x15','y15','z15','x16','y16','z16','x17','y17','z17','x18','y18','z18','x19','y19','z19','x20','y20','z20']]\n",
    "y_train = df_train['filename']\n",
    "y_train = y_train.map(lambda image: image.split('_')[2])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "X_test = df_test[['x0','y0','z0','x1','y1','z1','x2','y2','z2','x3','y3','z3','x4','y4','z4','x5','y5','z5','x6','y6','z6','x7','y7','z7','x8','y8','z8','x9','y9','z9','x10','y10','z10','x11','y11','z11','x12','y12','z12','x13','y13','z13','x14','y14','z14','x15','y15','z15','x16','y16','z16','x17','y17','z17','x18','y18','z18','x19','y19','z19','x20','y20','z20']]\n",
    "y_test = df_test['filename']\n",
    "y_test = y_test.map(lambda image: image.split('_')[2])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "X_validation = df_validation[['x0','y0','z0','x1','y1','z1','x2','y2','z2','x3','y3','z3','x4','y4','z4','x5','y5','z5','x6','y6','z6','x7','y7','z7','x8','y8','z8','x9','y9','z9','x10','y10','z10','x11','y11','z11','x12','y12','z12','x13','y13','z13','x14','y14','z14','x15','y15','z15','x16','y16','z16','x17','y17','z17','x18','y18','z18','x19','y19','z19','x20','y20','z20']]\n",
    "y_validation = df_validation['filename']\n",
    "y_validation = y_validation.map(lambda image: image.split('_')[2])\n",
    "X_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer, MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "!pip install dbTable\n",
    "from dbTable import dbTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listValidationScore = []\n",
    "listTestScore = []\n",
    "randomListValidationScore = []\n",
    "randomListTestScore = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_parameter = {\n",
    "    'n_neighbors': [1,2,3,4,5,6,7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto'],\n",
    "    'leaf_size': [1,2,3,4,5,6,7,8,9,10,11],\n",
    "    'p': [1, 2]  # 1 für Manhattan-Distanz, 2 für euklidische Distanz\n",
    "}\n",
    "knn_model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn_model, param_grid=knn_parameter, cv=20)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_knn_model = grid_search.best_estimator_\n",
    "grid_best_knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn_accuracy_validation = grid_best_knn_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_knn_accuracy_validation)\n",
    "grid_knn_accuracy = grid_best_knn_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_knn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=knn_model, param_distributions=knn_parameter, n_iter=10, cv=20, random_state=42)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_knn_model = random_search.best_estimator_\n",
    "random_best_knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_knn_accuracy_validation = random_best_knn_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_knn_accuracy_validation)\n",
    "random_knn_accuracy = random_best_knn_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_knn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_line = np.arange(1,9)\n",
    "train_accuracy =np.empty(len(KNN_line))\n",
    "test_accuracy = np.empty(len(KNN_line))\n",
    "validation_accuracy = np.empty(len(KNN_line))\n",
    "for i,k in enumerate(KNN_line):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    #Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test) \n",
    "\n",
    "    #Compute accuracy on the validation set\n",
    "    validation_accuracy[i] = knn.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "plt.title('k-NN Varying number of neighbors')\n",
    "plt.plot(KNN_line, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(KNN_line, train_accuracy, label='Training accuracy')\n",
    "plt.plot(KNN_line, validation_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "#KNeighbour(neighbours=3) 0.90 val 0.84 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = KNeighborsClassifier(n_neighbors=3)\n",
    "temp.fit(X_train, y_train)\n",
    "accuracy_validation = temp.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", accuracy_validation)\n",
    "accuracy = temp.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_parameter = {\n",
    "    'C': [50,56,57,58,59,60,61,62,70,100,125,130, 135], #range von 40 - 110\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'degree': [1,2,3],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "svc_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svc_model, param_grid=svc_parameter, cv=15)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_svc_model = grid_search.best_estimator_\n",
    "grid_best_svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit auf Testdaten: 0.9073170731707317\n"
     ]
    }
   ],
   "source": [
    "grid_svc_accuracy_validation = grid_best_svc_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_svc_accuracy_validation)\n",
    "grid_svc_accuracy = grid_best_svc_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_svc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=svc_model, param_distributions=svc_parameter, n_iter=10, cv=20, random_state=43)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_svc_model = random_search.best_estimator_\n",
    "random_best_svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_svc_accuracy_validation = random_best_svc_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_svc_accuracy_validation)\n",
    "random_svc_accuracy = random_best_svc_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_svc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_line = np.arange(70,160)#0.93717277486911\n",
    "train_accuracy =np.empty(len(SVC_line))\n",
    "test_accuracy = np.empty(len(SVC_line))\n",
    "validation_accuracy = np.empty(len(SVC_line))\n",
    "k=70\n",
    "for i,k in enumerate(SVC_line):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    svc_c = SVC(kernel='poly', C=k, probability=True, class_weight='balanced', degree=3, gamma='scale')\n",
    "    \n",
    "    #Fit the model\n",
    "    svc_c.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = svc_c.score(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = svc_c.score(X_test, y_test)\n",
    "\n",
    "    #Compute accuracy on the validation set\n",
    "    validation_accuracy[i] = svc_c.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "plt.title('SVC Varying C')\n",
    "plt.plot(SVC_line, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(SVC_line, train_accuracy, label='Training accuracy')\n",
    "plt.plot(SVC_line, validation_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.92, 1)\n",
    "plt.xlim(70,160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = SVC(kernel='poly', C=126, probability=True, class_weight='balanced', degree=3, gamma='scale')\n",
    "temp.fit(X_train, y_train)\n",
    "accuracy_validation = temp.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", accuracy_validation)\n",
    "accuracy = temp.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvc_parameter = {\n",
    "    'nu': np.arange(0, 0.2, 0.01),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [1, 2, 3, 4, 5],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "nusvc_model = NuSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=nusvc_model, param_grid=nusvc_parameter, cv=15)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_nusvc_model = grid_search.best_estimator_\n",
    "grid_best_nusvc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_nusvc_accuracy_validation = grid_best_nusvc_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_nusvc_accuracy_validation)\n",
    "grid_nusvc_accuracy = grid_best_nusvc_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_nusvc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=nusvc_model, param_distributions=nusvc_parameter, n_iter=10, cv=20, random_state=44)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_nusvc_model = random_search.best_estimator_\n",
    "random_best_nusvc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_nusvc_accuracy_validation = random_best_nusvc_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_nusvc_accuracy_validation)\n",
    "random_nusvc_accuracy = random_best_nusvc_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_nusvc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NuSVC_line = np.arange(0, 0.2, 0.01)\n",
    "train_accuracy = np.empty(len(NuSVC_line))\n",
    "test_accuracy = np.empty(len(NuSVC_line))\n",
    "validation_accuracy = np.empty(len(NuSVC_line))\n",
    "k = 0.1\n",
    "\n",
    "for i, nu_value in enumerate(NuSVC_line):\n",
    "    # Setup a knn classifier with k neighbors\n",
    "    nusvc_c = NuSVC(kernel='linear', nu=nu_value + 0.01, degree=4, gamma='auto')\n",
    "\n",
    "    # Fit the model\n",
    "    nusvc_c.fit(X_train, y_train)\n",
    "\n",
    "    # Compute accuracy on the training set\n",
    "    train_accuracy[i] = nusvc_c.score(X_train, y_train)\n",
    "\n",
    "    # Compute accuracy on the test set\n",
    "    test_accuracy[i] = nusvc_c.score(X_test, y_test)\n",
    "\n",
    "    # Compute accuracy on the validation set\n",
    "    validation_accuracy[i] = nusvc_c.score(X_validation, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "plt.title('NuSVC Varying nu (Random)')\n",
    "plt.plot(NuSVC_line, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(NuSVC_line, train_accuracy, label='Training accuracy')\n",
    "plt.plot(NuSVC_line, validation_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('nu')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim(0,0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NuSVC_line = np.arange(0, 0.2, 0.01)\n",
    "train_accuracy = np.empty(len(NuSVC_line))\n",
    "test_accuracy = np.empty(len(NuSVC_line))\n",
    "validation_accuracy = np.empty(len(NuSVC_line))\n",
    "k = 0.1\n",
    "\n",
    "for i, nu_value in enumerate(NuSVC_line):\n",
    "    # Setup a knn classifier with k neighbors\n",
    "    nusvc_c = NuSVC(kernel='poly', nu=nu_value + 0.01, probability=True, degree=3, gamma='scale')\n",
    "\n",
    "    # Fit the model\n",
    "    nusvc_c.fit(X_train, y_train)\n",
    "\n",
    "    # Compute accuracy on the training set\n",
    "    train_accuracy[i] = nusvc_c.score(X_train, y_train)\n",
    "\n",
    "    # Compute accuracy on the test set\n",
    "    test_accuracy[i] = nusvc_c.score(X_test, y_test)\n",
    "\n",
    "    # Compute accuracy on the validation set\n",
    "    validation_accuracy[i] = nusvc_c.score(X_validation, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "plt.title('NuSVC Varying nu')\n",
    "plt.plot(NuSVC_line, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(NuSVC_line, train_accuracy, label='Training accuracy')\n",
    "plt.plot(NuSVC_line, validation_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('nu')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim(0,0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nusvc_best= NuSVC(degree=3, gamma='scale', kernel='poly', nu=0.066)\n",
    "nusvc_best.fit(X_train, y_train)\n",
    "accuracy_validation = nusvc_best.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", accuracy_validation)\n",
    "accuracy = nusvc_best.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_parameter = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [1,2,3,4,5,6,7,8,9,10,11,None],\n",
    "    'min_samples_split': [5, 8, 9, 10],\n",
    "    'min_samples_leaf': [3, 4, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "}\n",
    "dt_model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=dt_parameter, cv=20)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_dt_model = grid_search.best_estimator_\n",
    "grid_best_dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dt_accuracy_validation = grid_best_dt_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_dt_accuracy_validation)\n",
    "grid_dt_accuracy = grid_best_dt_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_dt_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=dt_model, param_distributions=dt_parameter, n_iter=10, cv=20, random_state=44)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_dt_model = random_search.best_estimator_\n",
    "random_best_dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dt_accuracy_validation = random_best_dt_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_dt_accuracy_validation)\n",
    "random_dt_accuracy = random_best_dt_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_dt_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameter = {\n",
    "    'n_estimators': [ 100, 110, 120,130, 150],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [5, 6, 7, 9, 10, 11, 15],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "}\n",
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_parameter, cv=5)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_rf_model = grid_search.best_estimator_\n",
    "grid_best_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf_accuracy_validation = grid_best_rf_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_rf_accuracy_validation)\n",
    "grid_rf_accuracy = grid_best_rf_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=rf_parameter, n_iter=10, cv=20, random_state=43)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_rf_model = random_search.best_estimator_\n",
    "random_best_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rf_accuracy_validation = random_best_rf_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_rf_accuracy_validation)\n",
    "random_rf_accuracy = random_best_rf_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_line = np.arange(90,200)\n",
    "train_accuracy =np.empty(len(RandomForest_line))\n",
    "test_accuracy = np.empty(len(RandomForest_line))\n",
    "validation_accuracy = np.empty(len(RandomForest_line))\n",
    "k=90\n",
    "for i,k in enumerate(RandomForest_line):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    rf_c = RandomForestClassifier(n_estimators=k, criterion='log_loss', max_depth=None, min_samples_split=6, min_samples_leaf=2)\n",
    "    \n",
    "    #Fit the model\n",
    "    rf_c.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = rf_c.score(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = rf_c.score(X_test, y_test)\n",
    "\n",
    "    #Compute accuracy on the validation set\n",
    "    validation_accuracy[i] = rf_c.score(X_validation, y_validation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "plt.title('RandomForest Varying n_estimators')\n",
    "plt.plot(RandomForest_line, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(RandomForest_line, train_accuracy, label='Training accuracy')\n",
    "plt.plot(RandomForest_line, validation_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_parameter = {\n",
    "    'estimator': [None],\n",
    "    'n_estimators': [100, 150, 200, 250, 300, 400, 500],\n",
    "    'learning_rate': [0.09, 0.1, 0.11],\n",
    "    'algorithm': ['SAMME.R'],\n",
    "    'random_state': [None]\n",
    "}\n",
    "adaboost_model = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=adaboost_model, param_grid=ab_parameter, cv=20)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_ab_model = grid_search.best_estimator_\n",
    "grid_best_ab_model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ab_accuracy_validation = grid_best_ab_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_ab_accuracy_validation)\n",
    "grid_ab_accuracy = grid_best_ab_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_ab_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=adaboost_model, param_distributions=ab_parameter, n_iter=10, cv=20, random_state=42)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_ab_model = random_search.best_estimator_\n",
    "random_best_ab_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ab_accuracy_validation = random_best_ab_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_ab_accuracy_validation)\n",
    "random_ab_accuracy = random_best_ab_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_ab_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost_line = np.arange(210,260)\n",
    "train_accuracy =np.empty(len(AdaBoost_line))\n",
    "test_accuracy = np.empty(len(AdaBoost_line))\n",
    "validation_accuracy = np.empty(len(AdaBoost_line))\n",
    "k=210\n",
    "for i,k in enumerate(AdaBoost_line):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    ada_c = AdaBoostClassifier(n_estimators=k, learning_rate=0.1, algorithm='SAMME.R', random_state=None)\n",
    "    \n",
    "    #Fit the model\n",
    "    ada_c.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = ada_c.score(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = ada_c.score(X_test, y_test)\n",
    "\n",
    "    #Compute accuracy on the validation set\n",
    "    validation_accuracy[i] = ada_c.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "plt.title('AdaBoost Varying n_estimators')\n",
    "plt.plot(AdaBoost_line, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(AdaBoost_line, train_accuracy, label='Training accuracy')\n",
    "plt.plot(AdaBoost_line, validation_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_parameter = {\n",
    "    'loss': ['log_loss'],\n",
    "    'n_estimators': [50, 100, 200, 250,  300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'min_samples_split': [1, 2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "}\n",
    "gb_model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=gb_parameter, cv=2)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_gb_model = grid_search.best_estimator_\n",
    "grid_best_gb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gb_accuracy_validation = grid_best_gb_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_gb_accuracy_validation)\n",
    "grid_gb_accuracy = grid_best_gb_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_gb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=gb_model, param_distributions=gb_parameter, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_gb_model = random_search.best_estimator_\n",
    "random_best_gb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_gb_accuracy_validation = random_best_gb_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_gb_accuracy_validation)\n",
    "random_gb_accuracy = random_best_gb_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_gb_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostClassifier #Generate Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_parameter = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [400, 500, 600]\n",
    "}\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=lr_parameter, cv=2)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_lr_model = grid_search.best_estimator_\n",
    "grid_best_lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr_accuracy_validation = grid_best_lr_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_lr_accuracy_validation)\n",
    "grid_lr_accuracy = grid_best_lr_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=lr_model, param_distributions=lr_parameter, n_iter=60, cv=20, random_state=44)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_lr_model = random_search.best_estimator_\n",
    "random_best_lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lr_accuracy_validation = random_best_lr_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_lr_accuracy_validation)\n",
    "random_lr_accuracy = random_best_lr_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression_line = np.arange(470,530)\n",
    "train_accuracy =np.empty(len(LogisticRegression_line))\n",
    "test_accuracy = np.empty(len(LogisticRegression_line))\n",
    "validation_accuracy = np.empty(len(LogisticRegression_line))\n",
    "k=470\n",
    "for i,k in enumerate(LogisticRegression_line):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    lr_c = LogisticRegression(penalty = 'l1', C=3792.690190732246, solver = 'liblinear', max_iter = k)\n",
    "\n",
    "    #Fit the model\n",
    "    lr_c.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = lr_c.score(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = lr_c.score(X_test, y_test)\n",
    "\n",
    "    #Compute accuracy on the validation set\n",
    "    validation_accuracy[i] = lr_c.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Plot\n",
    "plt.title('LogisticRegression Varying C')\n",
    "plt.plot(LogisticRegression_line, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(LogisticRegression_line, train_accuracy, label='Training accuracy')\n",
    "plt.plot(LogisticRegression_line, validation_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('max_iter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_classifier = grid_best_knn_model, grid_best_svc_model, grid_best_nusvc_model, grid_best_dt_model, grid_best_rf_model, grid_best_ab_model, grid_best_gb_model, grid_best_lr_model, random_best_knn_model, random_best_svc_model, random_best_nusvc_model, random_best_dt_model, random_best_rf_model, random_best_ab_model, random_best_gb_model, random_best_lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_parameter = {\n",
    "    'scaler': [StandardScaler(),MinMaxScaler(),MaxAbsScaler(),RobustScaler()],\n",
    "    'classifier': [grid_best_knn_model, grid_best_svc_model, grid_best_nusvc_model, grid_best_dt_model, grid_best_rf_model,grid_best_ab_model, grid_best_gb_model, grid_best_lr_model, random_best_knn_model, random_best_svc_model, random_best_nusvc_model, random_best_dt_model, random_best_rf_model,random_best_ab_model, random_best_gb_model, random_best_lr_model]}\n",
    "pl_model = Pipeline(steps=[('scaler', StandardScaler()), ('classifier', grid_best_knn_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pl_model, param_grid=pl_parameter, cv=3)\n",
    "grid_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", grid_search.best_params_)\n",
    "grid_best_pl_model = grid_search.best_estimator_\n",
    "grid_best_pl_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pl_accuracy_validation = grid_best_pl_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", grid_pl_accuracy_validation)\n",
    "grid_pl_accuracy = grid_best_pl_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", grid_pl_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=pl_model, param_distributions=pl_parameter, n_iter=10, cv=20, random_state=42)\n",
    "random_search.fit(X_validation, y_validation)\n",
    "print(\"Beste Hyperparameter:\", random_search.best_params_)\n",
    "random_best_pl_model = random_search.best_estimator_\n",
    "random_best_pl_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pl_accuracy_validation = random_best_pl_model.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", random_pl_accuracy_validation)\n",
    "random_pl_accuracy = random_best_pl_model.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", random_pl_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(),MinMaxScaler(),MaxAbsScaler(),RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline_line = np.arange(len(pipeline_classifier))\n",
    "train_accuracy =np.empty(len(Pipeline_line))\n",
    "test_accuracy = np.empty(len(Pipeline_line))\n",
    "validation_accuracy = np.empty(len(Pipeline_line))\n",
    "k=0\n",
    "for i,k in enumerate(Pipeline_line):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    pl_c = Pipeline(steps=[('scaler', MinMaxScaler()), ('classifier', pipeline_classifier[k])])\n",
    "    \n",
    "    #Fit the model\n",
    "    pl_c.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = pl_c.score(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = pl_c.score(X_test, y_test)\n",
    "\n",
    "    #Compute accuracy on the validation set\n",
    "    validation_accuracy[i] = pl_c.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "plt.title('Pipeline Varying classifier')\n",
    "plt.plot(Pipeline_line, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(Pipeline_line, train_accuracy, label='Training accuracy')\n",
    "plt.plot(Pipeline_line, validation_accuracy, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ohne ParameterTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "nusvc = NuSVC()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "ab = AdaBoostClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the accuracy score and validation score of each model\n",
    "print(\"KNN\")\n",
    "knn.fit(X_train, y_train)\n",
    "knn_accuracy = knn.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", knn_accuracy)\n",
    "knn_accuracy_validation = knn.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", knn_accuracy_validation)\n",
    "print(\"SVC\")\n",
    "svc.fit(X_train, y_train)\n",
    "svc_accuracy = svc.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", svc_accuracy)\n",
    "svc_accuracy_validation = svc.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", svc_accuracy_validation)\n",
    "print(\"NuSVC\")\n",
    "nusvc.fit(X_train, y_train)\n",
    "nusvc_accuracy = nusvc.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", nusvc_accuracy)\n",
    "nusvc_accuracy_validation = nusvc.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", nusvc_accuracy_validation)\n",
    "print(\"DecisionTree\")\n",
    "dt.fit(X_train, y_train)\n",
    "dt_accuracy = dt.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", dt_accuracy)\n",
    "dt_accuracy_validation = dt.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", dt_accuracy_validation)\n",
    "print(\"RandomForest\")\n",
    "rf.fit(X_train, y_train)\n",
    "rf_accuracy = rf.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", rf_accuracy)\n",
    "rf_accuracy_validation = rf.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", rf_accuracy_validation)\n",
    "print(\"AdaBoost\")\n",
    "ab.fit(X_train, y_train)\n",
    "ab_accuracy = ab.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", ab_accuracy)\n",
    "ab_accuracy_validation = ab.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", ab_accuracy_validation)\n",
    "print(\"GradientBoosting\")\n",
    "gb.fit(X_train, y_train)\n",
    "gb_accuracy = gb.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", gb_accuracy)\n",
    "gb_accuracy_validation = gb.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", gb_accuracy_validation)\n",
    "print(\"LogisticRegression\")\n",
    "lr.fit(X_train, y_train)\n",
    "lr_accuracy = lr.score(X_test, y_test)\n",
    "print(\"Genauigkeit auf Testdaten:\", lr_accuracy)\n",
    "lr_accuracy_validation = lr.score(X_validation, y_validation)\n",
    "print(\"Genauigkeit auf Validierungsdaten:\", lr_accuracy_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = [\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"SVC\",\n",
    "    \"NuSVC\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"GradientBoostingClassifier\",\n",
    "    \"LogisticRegression\",\n",
    "    \"Pipeline\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbTable:\n",
    "    def __init__(self, name, columns):\n",
    "        self.name = name\n",
    "        self.columns = columns\n",
    "        self.data = []\n",
    "\n",
    "    def insert(self, *args):\n",
    "        row = dict(zip(self.columns, args))\n",
    "        self.data.append(row)\n",
    "\n",
    "    def printTable(self):\n",
    "        print(self.name)\n",
    "        for row in self.data:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_score = DbTable('grid_scores', ['name','Validation','Test'])\n",
    "grid_score.insert(Names[0],grid_knn_accuracy_validation,grid_knn_accuracy)\n",
    "grid_score.insert(Names[1],grid_svc_accuracy_validation,grid_svc_accuracy)\n",
    "grid_score.insert(Names[2],grid_nusvc_accuracy_validation,grid_nusvc_accuracy)\n",
    "grid_score.insert(Names[3],grid_dt_accuracy_validation,grid_dt_accuracy)\n",
    "grid_score.insert(Names[4],grid_rf_accuracy_validation,grid_rf_accuracy)\n",
    "grid_score.insert(Names[5],grid_ab_accuracy_validation,grid_ab_accuracy)\n",
    "grid_score.insert(Names[6],grid_gb_accuracy_validation,grid_gb_accuracy)\n",
    "grid_score.insert(Names[7],grid_lr_accuracy_validation,grid_lr_accuracy)\n",
    "grid_score.insert(Names[8],grid_pl_accuracy_validation,grid_pl_accuracy)\n",
    "grid_score.printTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_score = DbTable('random_scores',['name','Validation','Test'])\n",
    "random_score.insert(Names[0],random_knn_accuracy_validation,random_knn_accuracy)\n",
    "random_score.insert(Names[1],random_svc_accuracy_validation,random_svc_accuracy)\n",
    "random_score.insert(Names[2],random_nusvc_accuracy_validation,random_nusvc_accuracy)\n",
    "random_score.insert(Names[3],random_dt_accuracy_validation,random_dt_accuracy)\n",
    "random_score.insert(Names[4],random_rf_accuracy_validation,random_rf_accuracy)\n",
    "random_score.insert(Names[5],random_ab_accuracy_validation,random_ab_accuracy)\n",
    "random_score.insert(Names[6],random_gb_accuracy_validation,random_gb_accuracy)\n",
    "random_score.insert(Names[7],random_lr_accuracy_validation,random_lr_accuracy)\n",
    "random_score.insert(Names[8],random_pl_accuracy_validation,random_pl_accuracy)\n",
    "random_score.printTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best_knn_model.fit(X_train, y_train)\n",
    "grid_best_svc_model.fit(X_train, y_train)\n",
    "grid_best_nusvc_model.fit(X_train, y_train)\n",
    "grid_best_dt_model.fit(X_train, y_train)\n",
    "grid_best_rf_model.fit(X_train, y_train)\n",
    "grid_best_ab_model.fit(X_train, y_train)\n",
    "grid_best_gb_model.fit(X_train, y_train)\n",
    "grid_best_lr_model.fit(X_train, y_train)\n",
    "grid_best_pl_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_best_knn_model.fit(X_train, y_train)\n",
    "random_best_svc_model.fit(X_train, y_train)\n",
    "random_best_nusvc_model.fit(X_train, y_train)\n",
    "random_best_dt_model.fit(X_train, y_train)\n",
    "random_best_rf_model.fit(X_train, y_train)\n",
    "random_best_ab_model.fit(X_train, y_train)\n",
    "random_best_gb_model.fit(X_train, y_train)\n",
    "random_best_lr_model.fit(X_train, y_train)\n",
    "random_best_pl_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid = [\n",
    "    grid_best_knn_model.predict(X_test),\n",
    "    grid_best_svc_model.predict(X_test),\n",
    "    grid_best_nusvc_model.predict(X_test),\n",
    "    grid_best_dt_model.predict(X_test),\n",
    "    grid_best_rf_model.predict(X_test),\n",
    "    grid_best_ab_model.predict(X_test),\n",
    "    grid_best_gb_model.predict(X_test),\n",
    "    grid_best_lr_model.predict(X_test),\n",
    "    grid_best_pl_model.predict(X_test)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_random = [\n",
    "    random_best_knn_model.predict(X_test),\n",
    "    random_best_svc_model.predict(X_test),\n",
    "    random_best_nusvc_model.predict(X_test),\n",
    "    random_best_dt_model.predict(X_test),\n",
    "    random_best_rf_model.predict(X_test),\n",
    "    random_best_ab_model.predict(X_test),\n",
    "    random_best_gb_model.predict(X_test),\n",
    "    random_best_lr_model.predict(X_test),\n",
    "    random_best_pl_model.predict(X_test)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"spock\", \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "temp = AdaBoostClassifier()\n",
    "temp.fit(X_train, y_train)\n",
    "print(\"SVC\", temp.score(X_test, y_test))\n",
    "temp = temp.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, temp)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix AdaBoost (ohne Tuning)\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nusvc_best.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, tmp)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix NuSVC Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[0])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix KNN Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix SVC Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix NuSVC Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[3])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix DecisionTree Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[4])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix RandomForest Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[5])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix AdaBoost Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[6])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix GradientBoost Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[7])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix LogisticRegression Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_grid[8])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix PipeLine Grid\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[0])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix KNN Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix SVC Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[2])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix NuSVC Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[3])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix DecisionTree Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[4])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix RandomForest Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[5])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix AdaBoost Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[6])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix GradientBoost Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[7])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix LogisticRegression Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_random[8])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=class_names, yticklabels=class_names, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix PipeLine Random\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alexvenv310",
   "language": "python",
   "name": "alexvenv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
